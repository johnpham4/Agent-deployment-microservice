{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12995808,
          "sourceType": "datasetVersion",
          "datasetId": 8226207
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "255e5133c5ac49e38648d6bd84d9ebf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3cd4fd8dd3640e9b5663c72a68c6087",
              "IPY_MODEL_cfea18e8d0864a3e966fb91cd037d027",
              "IPY_MODEL_f8551e81fac44e50a572b86554cc340d"
            ],
            "layout": "IPY_MODEL_95b48be28d7e4e8f9f6ceb6d60ebf10b"
          }
        },
        "f3cd4fd8dd3640e9b5663c72a68c6087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93740782f3248f6819e9c70c8863dac",
            "placeholder": "​",
            "style": "IPY_MODEL_f64d326826444e0296738a17d8e5d22a",
            "value": "data/train-00000-of-00001.parquet:   0%"
          }
        },
        "cfea18e8d0864a3e966fb91cd037d027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d9e35a4849407d868a4574aef34e0f",
            "max": 21512161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e27a4e169dd74329978bb35b3f788741",
            "value": 0
          }
        },
        "f8551e81fac44e50a572b86554cc340d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7097fdd216b94192861773ed62d4764c",
            "placeholder": "​",
            "style": "IPY_MODEL_a2c618d239ce4b318e596d04b9cd3552",
            "value": " 0.00/21.5M [01:15&lt;?, ?B/s]"
          }
        },
        "95b48be28d7e4e8f9f6ceb6d60ebf10b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93740782f3248f6819e9c70c8863dac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64d326826444e0296738a17d8e5d22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96d9e35a4849407d868a4574aef34e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27a4e169dd74329978bb35b3f788741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7097fdd216b94192861773ed62d4764c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c618d239ce4b318e596d04b9cd3552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers accelerate bitsandbytes trl mlflow boto3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-15T03:48:13.777562Z",
          "iopub.execute_input": "2025-09-15T03:48:13.777810Z",
          "iopub.status.idle": "2025-09-15T03:49:48.575252Z",
          "shell.execute_reply.started": "2025-09-15T03:48:13.777786Z",
          "shell.execute_reply": "2025-09-15T03:49:48.574534Z"
        },
        "id": "yxTWejaxT5bx",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3b771c-d4b9-4f8c-c13b-8b3291192b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.2/738.2 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset, concatenate_datasets\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,          # AutoModel for language modeling tasks\n",
        "    AutoTokenizer,                # AutoTokenizer for tokenization\n",
        "    BitsAndBytesConfig,           # Configuration for BitsAndBytes\n",
        "    TrainingArguments,            # Training arguments for model training\n",
        "    TrainerCallback\n",
        ")\n",
        "from peft import LoraConfig, PeftModel,PeftConfig\n",
        "from trl import SFTTrainer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import logging as log\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from data_prep import get_dataset, tokenize_and_mask\n",
        "from peft_lora_config import Peft_Config\n",
        "\n",
        "def setup_logging():\n",
        "    # Remove all handlers associated with the root logger object.\n",
        "    for handler in log.root.handlers[:]:\n",
        "        log.root.removeHandler(handler)\n",
        "\n",
        "    log.basicConfig(\n",
        "        level=log.WARNING,\n",
        "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "        handlers=[log.StreamHandler()],\n",
        "    )\n",
        "\n",
        "logger = log.getLogger(__name__)\n",
        "setup_logging()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-15T03:49:48.576144Z",
          "iopub.execute_input": "2025-09-15T03:49:48.576404Z",
          "iopub.status.idle": "2025-09-15T03:50:25.256971Z",
          "shell.execute_reply.started": "2025-09-15T03:49:48.576366Z",
          "shell.execute_reply": "2025-09-15T03:50:25.256250Z"
        },
        "id": "ETQCU7ZekHZ-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset EDA"
      ],
      "metadata": {
        "id": "yQd8Hn-2AYNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"thangvip/vietnamese-legal-qa\", split=\"train\")"
      ],
      "metadata": {
        "id": "H8CQpO9BeP4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "255e5133c5ac49e38648d6bd84d9ebf2",
            "f3cd4fd8dd3640e9b5663c72a68c6087",
            "cfea18e8d0864a3e966fb91cd037d027",
            "f8551e81fac44e50a572b86554cc340d",
            "95b48be28d7e4e8f9f6ceb6d60ebf10b",
            "c93740782f3248f6819e9c70c8863dac",
            "f64d326826444e0296738a17d8e5d22a",
            "96d9e35a4849407d868a4574aef34e0f",
            "e27a4e169dd74329978bb35b3f788741",
            "7097fdd216b94192861773ed62d4764c",
            "a2c618d239ce4b318e596d04b9cd3552"
          ]
        },
        "outputId": "b6206792-df2d-4e20-b216-8f181fdef360"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/21.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "255e5133c5ac49e38648d6bd84d9ebf2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/307262ec6f3236d59158da295cccda3d346b7e7d4f6b57f759418b2962728b62",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1502436286.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Login using e.g. `huggingface-cli login` to access this dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thangvip/vietnamese-legal-qa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   1413\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                         \u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_proc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     self._download_and_prepare(\n\u001b[0m\u001b[1;32m    895\u001b[0m                         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                         \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0msplit_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0msplit_generators_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_split_generators_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0msplit_generators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msplit_generators_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# Checksums verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/packaged_modules/parquet/parquet.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"At least one data file must be specified, but got data_files={self.config.data_files}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_on_the_fly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mextracted_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_recorded_sizes_checksums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstack_multiprocessing_download_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             downloaded_path_or_paths = map_nested(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0mdownload_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0murl_or_urls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         mapped = [\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    406\u001b[0m             }\n\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     ):\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapped_item\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapped_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             return [\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0murl_or_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m# append the relative path to the base_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0murl_or_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_or_path_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracked_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mlibrary_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_datasets_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_hub_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                     \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolved_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolved_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5537\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5539\u001b[0;31m         return hf_hub_download(\n\u001b[0m\u001b[1;32m   5540\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5541\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         )\n\u001b[1;32m   1009\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1011\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         _download_to_tmp_and_move(\n\u001b[0m\u001b[1;32m   1172\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".incomplete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m             \u001b[0mdestination_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mxet_file_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_xet_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xet Storage is enabled for this repo. Downloading file from Xet Storage..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m             xet_get(\n\u001b[0m\u001b[1;32m   1724\u001b[0m                 \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincomplete_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                 \u001b[0mxet_file_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxet_file_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         download_files(\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0mxet_download_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/307262ec6f3236d59158da295cccda3d346b7e7d4f6b57f759418b2962728b62"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.shape"
      ],
      "metadata": {
        "id": "XICqnbvDh5TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "\n",
        "for i in tqdm(range(len(ds))):\n",
        "    qa_pairs = ds[i][\"generated_qa_pairs\"]\n",
        "    for qa_pair in qa_pairs:\n",
        "        rows.append({\n",
        "            \"question\": qa_pair[\"question\"],\n",
        "            \"answer\": qa_pair[\"answer\"]\n",
        "        })\n",
        "\n",
        "# Tạo DataFrame 1 lần\n",
        "dataframe = pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "tma_Yvisfi0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataframe.assign(\n",
        "    num_tokens=dataframe[\"answer\"].apply(lambda text: len(str(text).split()))\n",
        ")\n",
        "\n",
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#     display(dataframe.sample(10))"
      ],
      "metadata": {
        "id": "89drwizgiiZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(df[\"num_tokens\"], bins=30, color=\"skyblue\", edgecolor=\"white\")\n",
        "plt.xticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iBuPU3PvhVht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"size: {df.loc[df['num_tokens'] <= 256].size}\")\n",
        "df = df.loc[df[\"num_tokens\"] < 256]\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "nTydeiBvhoNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up PEFT and Lora Configs"
      ],
      "metadata": {
        "id": "SEg0JONDAQR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = Peft_Config()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:31:45.425656Z",
          "iopub.execute_input": "2025-09-14T19:31:45.425990Z",
          "iopub.status.idle": "2025-09-14T19:31:45.439216Z",
          "shell.execute_reply.started": "2025-09-14T19:31:45.425969Z",
          "shell.execute_reply": "2025-09-14T19:31:45.438555Z"
        },
        "id": "l5HV6N48kRhL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 :Load tokenizer and model with QLoRA configuration\n",
        "compute_dtype = getattr(torch, config.bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=config.use_4bit,\n",
        "    bnb_4bit_quant_type=config.bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=config.use_nested_quant,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:31:45.439948Z",
          "iopub.execute_input": "2025-09-14T19:31:45.440238Z",
          "iopub.status.idle": "2025-09-14T19:31:45.451393Z",
          "shell.execute_reply.started": "2025-09-14T19:31:45.440216Z",
          "shell.execute_reply": "2025-09-14T19:31:45.450729Z"
        },
        "id": "tEIaKdg2kXUa",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 :Check GPU compatibility with bfloat16\n",
        "if compute_dtype == torch.float16 and config.use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:31:45.452078Z",
          "iopub.execute_input": "2025-09-14T19:31:45.452266Z",
          "iopub.status.idle": "2025-09-14T19:31:45.465512Z",
          "shell.execute_reply.started": "2025-09-14T19:31:45.452252Z",
          "shell.execute_reply": "2025-09-14T19:31:45.464847Z"
        },
        "id": "mC93omh-kXoK",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4 :Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=config.device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "id": "lrTEsn49Q7qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5 :Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name, trust_remote_code=True)\n",
        "\n",
        "special_tokens = {\"additional_special_tokens\": [\"<|system|>\", \"<|user|>\", \"<|assistant|>\"]}\n",
        "tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "tokenizer.chat_template = \"\"\"{% for message in messages %}\n",
        "{% if message['role'] == 'system' %}\n",
        "<|system|>\n",
        "{{ message['content'].strip() }}\n",
        "{{ eos_token }}\n",
        "{% elif message['role'] == 'user' %}\n",
        "<|user|>\n",
        "{{ message['content'].strip() }}\n",
        "{{ eos_token }}\n",
        "{% elif message['role'] == 'assistant' %}\n",
        "<|assistant|>\n",
        "{{ message['content'].strip() }}\n",
        "{{ eos_token }}\n",
        "{% endif %}\n",
        "{% endfor %}\n",
        "{% if add_generation_prompt %}\n",
        "<|assistant|>\n",
        "{% endif %}\"\"\"\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.bos_token_id = tokenizer.bos_token_id\n",
        "model.config.eos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:34:14.023693Z",
          "iopub.execute_input": "2025-09-14T19:34:14.023957Z",
          "iopub.status.idle": "2025-09-14T19:34:16.712448Z",
          "shell.execute_reply.started": "2025-09-14T19:34:14.023932Z",
          "shell.execute_reply": "2025-09-14T19:34:16.711661Z"
        },
        "id": "RC0LZ8veXCzh",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6 :Load LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=config.lora_alpha,\n",
        "    lora_dropout=config.lora_dropout,\n",
        "    r=config.lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:34:16.713223Z",
          "iopub.execute_input": "2025-09-14T19:34:16.713467Z",
          "iopub.status.idle": "2025-09-14T19:34:16.717634Z",
          "shell.execute_reply.started": "2025-09-14T19:34:16.713443Z",
          "shell.execute_reply": "2025-09-14T19:34:16.716941Z"
        },
        "id": "PY6Tp4TBXGXR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## s3 Config"
      ],
      "metadata": {
        "id": "47Jr9lDtWszF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "S3_BUCKET = \"mlflow-artifacts-monitor\"\n",
        "s3_client = boto3.client(\n",
        "    \"s3\",\n",
        "    aws_access_key_id=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
        "    aws_secret_access_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
        "    region_name=os.environ[\"AWS_DEFAULT_REGION\"]\n",
        ")"
      ],
      "metadata": {
        "id": "u3CcO-RrWu6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mlflow tracking"
      ],
      "metadata": {
        "id": "lhRym1YqW4pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlflow set tracking\n",
        "url = \"https://victoria-communicable-sometimes.ngrok-free.dev\"\n",
        "mlflow.set_tracking_uri(url)\n",
        "tracking_uri = mlflow.get_tracking_uri()\n",
        "print(f\"Current tracking uri: {tracking_uri}\")"
      ],
      "metadata": {
        "id": "t_ifaFcUf8up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"healthcarechatbot\")"
      ],
      "metadata": {
        "id": "z6JFNadSJ6Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training config"
      ],
      "metadata": {
        "id": "f9UA85YiVP5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7 : Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    # --- Logging ---\n",
        "    report_to=\"mlflow\",\n",
        "    run_name=f\"{config.model_name_finetuned}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%s')}\",\n",
        "\n",
        "    # --- Paths & Core training ---\n",
        "    output_dir=config.output_dir,\n",
        "    num_train_epochs=config.num_train_epochs,\n",
        "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
        "    optim=config.optim,\n",
        "    save_steps=config.save_steps,\n",
        "    logging_steps=config.logging_steps,\n",
        "    learning_rate=config.learning_rate,\n",
        "    weight_decay=config.weight_decay,\n",
        "    fp16=config.fp16,\n",
        "    bf16=config.bf16,\n",
        "    max_grad_norm=config.max_grad_norm,\n",
        "    max_steps=config.max_steps,\n",
        "    warmup_ratio=config.warmup_ratio,\n",
        "    group_by_length=config.group_by_length,\n",
        "    lr_scheduler_type=config.lr_scheduler_type,\n",
        "\n",
        "    # --- val ---\n",
        "    eval_steps=200,\n",
        "    save_strategy=\"steps\",\n",
        "    eval_strategy=\"steps\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\"\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:34:16.718436Z",
          "iopub.execute_input": "2025-09-14T19:34:16.718689Z",
          "iopub.status.idle": "2025-09-14T19:34:16.774099Z",
          "shell.execute_reply.started": "2025-09-14T19:34:16.718667Z",
          "shell.execute_reply": "2025-09-14T19:34:16.773519Z"
        },
        "id": "Qfm8ALUKXHj0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train, ds_val = get_dataset()\n",
        "\n",
        "message = ds_train['messages']\n",
        "\n",
        "tokenized_chat = tokenizer.apply_chat_template(message, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "print(tokenizer.decode(tokenized_chat[0]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:34:16.775012Z",
          "iopub.execute_input": "2025-09-14T19:34:16.775290Z",
          "iopub.status.idle": "2025-09-14T19:34:27.243645Z",
          "shell.execute_reply.started": "2025-09-14T19:34:16.775239Z",
          "shell.execute_reply": "2025-09-14T19:34:27.242835Z"
        },
        "id": "QHS7ptF2AyAh",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train"
      ],
      "metadata": {
        "id": "Aj5SvugItegE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train[0][\"messages\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-14T19:34:27.244556Z",
          "iopub.execute_input": "2025-09-14T19:34:27.244815Z",
          "iopub.status.idle": "2025-09-14T19:34:27.250780Z",
          "shell.execute_reply.started": "2025-09-14T19:34:27.244798Z",
          "shell.execute_reply": "2025-09-14T19:34:27.249970Z"
        },
        "id": "rGuJYMQ6YhTs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from mlflow.models import infer_signature\n",
        "\n",
        "sample = ds_train[0][\"messages\"]\n",
        "\n",
        "# MLflow infers schema from the provided sample input/output/params\n",
        "signature = infer_signature(\n",
        "  model_input=sample[0][\"content\"],\n",
        "  model_output=sample[1][\"content\"],\n",
        "  # Parameters are saved with default values if specified\n",
        "  params={\"max_new_tokens\": 256, \"repetition_penalty\": 1.15, \"return_full_text\": False},\n",
        ")\n",
        "\n",
        "signature"
      ],
      "metadata": {
        "id": "08sU6tAtcjWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 1024\n",
        "\n",
        "# Apply mapping (non-batched for simplicity; batched mapping can be used for speed)\n",
        "tokenized = ds_train.map(\n",
        "    lambda example: tokenize_and_mask(example, tokenizer, max_length), remove_columns=[\"messages\"])\n",
        "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "train_dataset = tokenized\n",
        "\n",
        "tokenized = ds_val.map(\n",
        "    lambda example: tokenize_and_mask(example, tokenizer, max_length), remove_columns=[\"messages\"])\n",
        "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "val_dataset = tokenized"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-14T19:34:27.251758Z",
          "iopub.execute_input": "2025-09-14T19:34:27.252054Z",
          "iopub.status.idle": "2025-09-14T19:35:01.448198Z",
          "shell.execute_reply.started": "2025-09-14T19:34:27.252030Z",
          "shell.execute_reply": "2025-09-14T19:35:01.446612Z"
        },
        "id": "N7OU1X0MYhTt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-14T19:35:01.454211Z",
          "iopub.execute_input": "2025-09-14T19:35:01.454723Z",
          "iopub.status.idle": "2025-09-14T19:35:01.477529Z",
          "shell.execute_reply.started": "2025-09-14T19:35:01.454691Z",
          "shell.execute_reply": "2025-09-14T19:35:01.476816Z"
        },
        "id": "aJUl3XNGYhTt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "3xsuQP3ZVdyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# Step 8 :Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    peft_config=peft_config,\n",
        "    args=training_arguments,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:35:01.478220Z",
          "iopub.execute_input": "2025-09-14T19:35:01.478480Z",
          "iopub.status.idle": "2025-09-14T19:35:04.827553Z",
          "shell.execute_reply.started": "2025-09-14T19:35:01.478457Z",
          "shell.execute_reply": "2025-09-14T19:35:04.826775Z"
        },
        "id": "EloFw7GuXI73",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class MLflowLossCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            for k, v in logs.items():\n",
        "                if isinstance(v, (int, float)):\n",
        "                    mlflow.log_metric(k, v, step=state.global_step)\n",
        "\n",
        "trainer.add_callback(MLflowLossCallback)"
      ],
      "metadata": {
        "id": "jpH0899giYRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run() as run:\n",
        "    trainer.train()\n",
        "\n",
        "    # --- Step 9: Log training loss curve ---\n",
        "    history = trainer.state.log_history\n",
        "    steps = [h[\"step\"] for h in history if \"loss\" in h]\n",
        "    losses = [h[\"loss\"] for h in history if \"loss\" in h]\n",
        "\n",
        "    for step, loss in zip(steps, losses):\n",
        "        mlflow.log_metric(\"train_loss\", loss, step=step)\n",
        "\n",
        "    # --- Step 10: Save trained adapter model (checkpoint) ---\n",
        "    checkpoint_dir = \"checkpoint_model\"\n",
        "    trainer.model.save_pretrained(checkpoint_dir)\n",
        "    tokenizer.save_pretrained(checkpoint_dir)\n",
        "\n",
        "    # --- Step 11: Merge and save final model with adapter ---\n",
        "    model = trainer.model\n",
        "    if hasattr(model, \"merge_and_unload\"):\n",
        "        base_model = AutoModelForCausalLM.from_pretrained(\n",
        "            config.model_name,\n",
        "            dtype=\"float32\",\n",
        "            device_map=config.device_map\n",
        "        )\n",
        "        base_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "        model = PeftModel.from_pretrained(base_model, checkpoint_dir)\n",
        "        model = model.merge_and_unload()\n",
        "\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "        model.config.eos_token_id = tokenizer.eos_token_id\n",
        "        model.config.bos_token_id = tokenizer.bos_token_id\n",
        "\n",
        "    merged_dir = \"merged_model\"\n",
        "    model.save_pretrained(merged_dir)\n",
        "    tokenizer.save_pretrained(merged_dir)\n",
        "\n",
        "    # --- Step 12: Upload merged model to S3 ---\n",
        "    s3_client = boto3.client(\"s3\")\n",
        "    bucket = \"mlflow-artifacts-monitor\"\n",
        "    s3_prefix = f\"models/health-llm/{run.info.run_id}\"\n",
        "\n",
        "    for root, _, files in os.walk(merged_dir):\n",
        "        for f in files:\n",
        "            path = os.path.join(root, f)\n",
        "            key = f\"{s3_prefix}/{os.path.relpath(path, merged_dir)}\"\n",
        "            s3_client.upload_file(path, bucket, key)\n",
        "\n",
        "    model_uri = f\"s3://{bucket}/{s3_prefix}\"\n",
        "\n",
        "    # --- Step 13: Register the model metadata in MLflow ---\n",
        "    REGISTERED_MODEL_NAME = \"health-llm\"\n",
        "\n",
        "    result = mlflow.register_model(\n",
        "        model_uri=model_uri,\n",
        "        name=REGISTERED_MODEL_NAME\n",
        "    )\n",
        "\n",
        "    # --- Step 14: Update metadata and tags ---\n",
        "    client = MlflowClient()\n",
        "\n",
        "    client.set_registered_model_tag(\n",
        "        name=REGISTERED_MODEL_NAME, key=\"use_case\", value=\"patient_service\"\n",
        "    )\n",
        "\n",
        "    client.update_registered_model(\n",
        "        name=REGISTERED_MODEL_NAME,\n",
        "        description=\"A health-specific chatbot about daily Vietnamese sickness questions\"\n",
        "    )\n",
        "\n",
        "    client.set_model_version_tag(\n",
        "        name=REGISTERED_MODEL_NAME,\n",
        "        version=result.version,\n",
        "        key=\"validation_status\",\n",
        "        value=\"testing\",\n",
        "    )\n",
        "\n",
        "    # --- Step 15: Create alias for easier reference ---\n",
        "    client.set_registered_model_alias(\n",
        "        name=REGISTERED_MODEL_NAME,\n",
        "        alias=\"champion\",\n",
        "        version=result.version,\n",
        "    )\n",
        "\n",
        "    print(f\"Model registered successfully: version {result.version}\")\n",
        "    print(f\"S3 path: {model_uri}\")\n",
        "    print(f\"MLflow tracking: {run.info.run_id}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-14T19:35:04.828336Z",
          "iopub.execute_input": "2025-09-14T19:35:04.828573Z",
          "iopub.status.idle": "2025-09-14T19:35:22.838538Z",
          "shell.execute_reply.started": "2025-09-14T19:35:04.828551Z",
          "shell.execute_reply": "2025-09-14T19:35:22.837388Z"
        },
        "id": "cFGQPOUfXKtG",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}