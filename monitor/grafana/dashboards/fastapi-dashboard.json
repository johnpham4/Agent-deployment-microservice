{
  "dashboard": {
    "id": null,
    "title": "FastAPI LLM Chat Service Monitoring",
    "tags": ["fastapi", "llm", "chat", "monitoring"],
    "style": "dark",
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Service Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"fastapi-app\"}",
            "refId": "A",
            "legendFormat": "Service Status"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "mappings": [
              {
                "options": {
                  "0": {
                    "text": "DOWN"
                  },
                  "1": {
                    "text": "UP"
                  }
                },
                "type": "value"
              }
            ],
            "thresholds": {
              "steps": [
                {
                  "color": "red",
                  "value": 0
                },
                {
                  "color": "green",
                  "value": 1
                }
              ]
            }
          }
        },
        "gridPos": {
          "h": 4,
          "w": 6,
          "x": 0,
          "y": 0
        }
      },
      {
        "id": 2,
        "title": "Model Status",
        "type": "stat",
        "targets": [
          {
            "expr": "model_loaded",
            "refId": "A",
            "legendFormat": "Model Loaded"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "mappings": [
              {
                "options": {
                  "0": {
                    "text": "NOT LOADED"
                  },
                  "1": {
                    "text": "LOADED"
                  }
                },
                "type": "value"
              }
            ],
            "thresholds": {
              "steps": [
                {
                  "color": "red",
                  "value": 0
                },
                {
                  "color": "green",
                  "value": 1
                }
              ]
            }
          }
        },
        "gridPos": {
          "h": 4,
          "w": 6,
          "x": 6,
          "y": 0
        }
      },
      {
        "id": 3,
        "title": "Total Requests",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(chat_requests_total[5m]))",
            "refId": "A",
            "legendFormat": "Requests/sec"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "palette-classic"
            },
            "unit": "reqps"
          }
        },
        "gridPos": {
          "h": 4,
          "w": 6,
          "x": 12,
          "y": 0
        }
      },
      {
        "id": 4,
        "title": "Error Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(chat_requests_total{status_code!~\"2..\"}[5m])) / sum(rate(chat_requests_total[5m])) * 100",
            "refId": "A",
            "legendFormat": "Error Rate %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "unit": "percent",
            "thresholds": {
              "steps": [
                {
                  "color": "green",
                  "value": 0
                },
                {
                  "color": "yellow",
                  "value": 5
                },
                {
                  "color": "red",
                  "value": 10
                }
              ]
            }
          }
        },
        "gridPos": {
          "h": 4,
          "w": 6,
          "x": 18,
          "y": 0
        }
      },
      {
        "id": 5,
        "title": "Request Rate by Endpoint",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(chat_requests_total[5m])) by (endpoint)",
            "refId": "A",
            "legendFormat": "{{endpoint}}"
          }
        ],
        "yAxes": [
          {
            "label": "Requests/sec",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 4
        }
      },
      {
        "id": 6,
        "title": "Response Time Distribution",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(chat_request_duration_seconds_bucket[5m])) by (le))",
            "refId": "A",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.90, sum(rate(chat_request_duration_seconds_bucket[5m])) by (le))",
            "refId": "B",
            "legendFormat": "90th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, sum(rate(chat_request_duration_seconds_bucket[5m])) by (le))",
            "refId": "C",
            "legendFormat": "99th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "Duration (s)",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 4
        }
      },
      {
        "id": 7,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "memory_usage_bytes / 1024 / 1024",
            "refId": "A",
            "legendFormat": "Memory Usage (MB)"
          }
        ],
        "yAxes": [
          {
            "label": "Memory (MB)",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 12
        }
      },
      {
        "id": 8,
        "title": "CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "cpu_usage_percent",
            "refId": "A",
            "legendFormat": "CPU Usage %"
          }
        ],
        "yAxes": [
          {
            "label": "CPU %",
            "min": 0,
            "max": 100
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 12
        }
      },
      {
        "id": 9,
        "title": "Model Inference Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(model_inference_duration_seconds_bucket[5m])) by (le))",
            "refId": "A",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.90, sum(rate(model_inference_duration_seconds_bucket[5m])) by (le))",
            "refId": "B",
            "legendFormat": "90th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, sum(rate(model_inference_duration_seconds_bucket[5m])) by (le))",
            "refId": "C",
            "legendFormat": "99th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "Duration (s)",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 20
        }
      },
      {
        "id": 10,
        "title": "Tokens Generated",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(tokens_generated_total[5m])",
            "refId": "A",
            "legendFormat": "Tokens/sec"
          }
        ],
        "yAxes": [
          {
            "label": "Tokens/sec",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 20
        }
      },
      {
        "id": 11,
        "title": "Error Rate by Type",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(errors_total[5m])) by (error_type)",
            "refId": "A",
            "legendFormat": "{{error_type}}"
          }
        ],
        "yAxes": [
          {
            "label": "Errors/sec",
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 28
        }
      },
      {
        "id": 12,
        "title": "HTTP Status Codes",
        "type": "piechart",
        "targets": [
          {
            "expr": "sum(rate(chat_requests_total[5m])) by (status_code)",
            "refId": "A",
            "legendFormat": "{{status_code}}"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 28
        }
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "timepicker": {},
    "uid": "fastapi-llm-chat",
    "version": 1,
    "weekStart": ""
  }
}